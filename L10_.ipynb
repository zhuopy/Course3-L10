{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "L10_ZhuoyuPeng.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5nHYrGs4lLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import dataset\n",
        "import keras\n",
        "from keras.datasets import reuters"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyH5V3SV4nOg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "bea02887-1e77-4ce4-ab95-a66eb2e08ef5"
      },
      "source": [
        "# split dataset\n",
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=None, test_split=0.2)\n",
        "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
        "\n",
        "print('# of Training Samples: {}'.format(len(x_train)))\n",
        "print('# of Test Samples: {}'.format(len(x_test)))\n",
        "\n",
        "num_classes = max(y_train) + 1\n",
        "print('# of Classes: {}'.format(num_classes))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of Training Samples: 8982\n",
            "# of Test Samples: 2246\n",
            "# of Classes: 46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L85QogG4o6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#map index to words\n",
        "index_to_word = {}\n",
        "for key, value in word_index.items():\n",
        "    index_to_word[value] = key"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAaseYlg4zk0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b6f493c5-b2c5-4099-a6cb-c2b4384c5577"
      },
      "source": [
        "print(' '.join([index_to_word[x] for x in x_train[0]]))\n",
        "print(y_train[0])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the wattie nondiscriminatory mln loss for plc said at only ended said commonwealth could 1 traders now april 0 a after said from 1985 and from foreign 000 april 0 prices its account year a but in this mln home an states earlier and rise and revs vs 000 its 16 vs 000 a but 3 psbr oils several and shareholders and dividend vs 000 its all 4 vs 000 1 mln agreed largely april 0 are 2 states will billion total and against 000 pct dlrs\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vkh-05R0F1g",
        "colab_type": "text"
      },
      "source": [
        "Next, we need to binarize our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0zcRc7B40Wl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "max_words = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
        "x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3W_LH4L42Au",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "91e8ad7a-3695-4e38-9041-834d1c0b8526"
      },
      "source": [
        "print(x_train[0])\n",
        "print(len(x_train[0]))\n",
        "\n",
        "print(y_train[0])\n",
        "print(len(y_train[0]))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0.\n",
            " 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0.\n",
            " 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "100\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUkh5fWjBEI1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9fe5646a-ee4f-49d0-ece1-30477232fb73"
      },
      "source": [
        "#check out the types of train data\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8982, 100)\n",
            "(8982, 46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVJok4Rx43rl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "8698ca4b-00e6-4a59-d3d5-c866c836fa63"
      },
      "source": [
        "#construct model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "embedding_vecor_length = 100\n",
        "max_review_length =100\n",
        "num_of_words=100\n",
        "model = Sequential()\n",
        "model.add(keras.layers.Embedding(num_of_words, embedding_vecor_length, input_length=max_review_length))\n",
        "model.add(keras.layers.LSTM(64,activation=\"tanh\")) #with one LSTM layer\n",
        "model.add(keras.layers.Dense(46, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=3, batch_size=3)\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "2994/2994 [==============================] - 108s 36ms/step - loss: 2.4208 - accuracy: 0.3499 - val_loss: 2.3611 - val_accuracy: 0.3620\n",
            "Epoch 2/3\n",
            "2994/2994 [==============================] - 106s 35ms/step - loss: 2.2542 - accuracy: 0.4127 - val_loss: 2.1434 - val_accuracy: 0.4844\n",
            "Epoch 3/3\n",
            "2994/2994 [==============================] - 107s 36ms/step - loss: 2.0884 - accuracy: 0.4773 - val_loss: 2.0597 - val_accuracy: 0.4907\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f00af7af6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFWVRueBtdZE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "58ebb10d-e2a6-46fc-a568-7373e3f0d407"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "71/71 [==============================] - 1s 15ms/step - loss: 2.0597 - accuracy: 0.4907\n",
            "Test loss: 2.0597403049468994\n",
            "Test accuracy: 0.4906500577926636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gq2Y7lEJE_M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "e9a33b9c-44f4-4992-e322-87fa8a76fa1d"
      },
      "source": [
        "#construct the model\n",
        "model = Sequential()\n",
        "model.add(keras.layers.Embedding(num_of_words, embedding_vecor_length, input_length=max_review_length))\n",
        "model.add(keras.layers.LSTM(64,activation=\"tanh\",return_sequences=True)) #with three LSTM layer\n",
        "model.add(keras.layers.LSTM(64,activation=\"tanh\",return_sequences=True))\n",
        "model.add(keras.layers.LSTM(64,activation=\"tanh\"))\n",
        "model.add(keras.layers.Dense(46, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=3, batch_size=3)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "2994/2994 [==============================] - 292s 98ms/step - loss: 2.4341 - accuracy: 0.3496 - val_loss: 2.4091 - val_accuracy: 0.3620\n",
            "Epoch 2/3\n",
            "2994/2994 [==============================] - 296s 99ms/step - loss: 2.3236 - accuracy: 0.3975 - val_loss: 2.3089 - val_accuracy: 0.4270\n",
            "Epoch 3/3\n",
            "2994/2994 [==============================] - 296s 99ms/step - loss: 2.1503 - accuracy: 0.4554 - val_loss: 2.0536 - val_accuracy: 0.4782\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f009b8c0518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbbAI1t6ths6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e440785d-cb54-46bf-c791-9bfeac1f1354"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "71/71 [==============================] - 3s 41ms/step - loss: 2.0536 - accuracy: 0.4782\n",
            "Test loss: 2.053628921508789\n",
            "Test accuracy: 0.47818344831466675\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6KYgmEXVwp6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "e6ef3192-a780-4514-d1c0-4e27087d94b0"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(keras.layers.Embedding(num_of_words, embedding_vecor_length, input_length=max_review_length))\n",
        "model.add(keras.layers.LSTM(64,activation=\"tanh\")) #with one LSTM layer and one dropout layer\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(46, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=3, batch_size=3)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "2994/2994 [==============================] - 108s 36ms/step - loss: 2.4768 - accuracy: 0.3422 - val_loss: 2.3824 - val_accuracy: 0.3620\n",
            "Epoch 2/3\n",
            "2994/2994 [==============================] - 109s 36ms/step - loss: 2.3960 - accuracy: 0.3614 - val_loss: 2.3417 - val_accuracy: 0.3967\n",
            "Epoch 3/3\n",
            "2994/2994 [==============================] - 109s 36ms/step - loss: 2.3241 - accuracy: 0.4088 - val_loss: 2.2134 - val_accuracy: 0.4430\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f00a72a3b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8gU4Qys46He",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "542d5e45-4eba-49b8-8b32-4da3c4845e47"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "71/71 [==============================] - 1s 15ms/step - loss: 2.2134 - accuracy: 0.4430\n",
            "Test loss: 2.213419198989868\n",
            "Test accuracy: 0.44300979375839233\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfnglzO649cY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "7138ae18-86c2-4ca8-a021-7461af46ed5f"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(keras.layers.Embedding(num_of_words, embedding_vecor_length, input_length=max_review_length))\n",
        "model.add(keras.layers.LSTM(128,activation=\"tanh\")) #with one LSTM layer\n",
        "model.add(keras.layers.Dense(46, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=3, batch_size=3)\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "2994/2994 [==============================] - 194s 65ms/step - loss: 2.4189 - accuracy: 0.3510 - val_loss: 2.3546 - val_accuracy: 0.3856\n",
            "Epoch 2/3\n",
            "2994/2994 [==============================] - 192s 64ms/step - loss: 2.3205 - accuracy: 0.3929 - val_loss: 2.2642 - val_accuracy: 0.4359\n",
            "Epoch 3/3\n",
            "2994/2994 [==============================] - 192s 64ms/step - loss: 2.1987 - accuracy: 0.4424 - val_loss: 2.1598 - val_accuracy: 0.4519\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f009c18de10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4Mr4uBfz1IT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "c55e0451-20bf-40cc-a3ed-2f1e01849c63"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "71/71 [==============================] - 2s 33ms/step - loss: 2.1598 - accuracy: 0.4519\n",
            "Test loss: 2.1598076820373535\n",
            "Test accuracy: 0.451914519071579\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_dLzb_l1R9a",
        "colab_type": "text"
      },
      "source": [
        "### Summary\n",
        "Using one layer LSTM with 64 units has accuracy to be 0.49\n",
        "\n",
        "The first atttemp I tried is to increase the number of LSTM layer, however, the accuracy decreased. \n",
        "\n",
        "The second attemp I made is to use dropout layer with single LSTM layer, however, the accuracy decreased. \n",
        "\n",
        "The last attemp I made is using sing LSTM layer with 128 units (double units comprared to the original model), however, the accuracy decreased. \n",
        "\n",
        "Overall, the simplest model with fewer units give the best accuracy. RNN, or other neural network is black box algorithm, adjusting the hyperparameters are tricky and challenging. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDSqrAow2jCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}